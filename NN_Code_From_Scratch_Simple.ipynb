{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "data.keys()\n",
    "df = pd.DataFrame(data = data['data'],columns = data['feature_names'])\n",
    "X = np.array(df)\n",
    "y = np.array(data['target'])\n",
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(X, y)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where((y == 0) | (y == 1))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reduce to a 2 class problem\n",
    "X = X[np.where((y == 0) | (y == 1))[0]]\n",
    "y = y[np.where((y == 0) | (y == 1))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X,y)\n",
    "print(cross_val_score(clf, X, y)) \n",
    "\n",
    "#Perfect separation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use PCA to visualize:\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_plot = pca.fit_transform(X)\n",
    "X_plot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111de8e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(X_plot[np.where(y==0)].T[0],X_plot[np.where(y==0)].T[1])\n",
    "ax.scatter(X_plot[np.where(y==1)].T[0],X_plot[np.where(y==1)].T[1]);\n",
    "#We can see the the classes are perfectly separated when projected into 2 dimentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now on to the Neural Network:\n",
    "\n",
    "#Helper Functions\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def d_sigmoid(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def d_tanh(x):\n",
    "    return 1-np.tanh(x)**2\n",
    "\n",
    "\n",
    "def MSE(y_output,y_actual):\n",
    "    n = len(y_actual)\n",
    "    return np.sum((y_output.T-y_actual)**2)/n\n",
    "\n",
    "\n",
    "def d_MSE(y_output,y_actual):\n",
    "    n = len(y_actual)\n",
    "    return (2/n)*np.sum(y_output-y_actual)\n",
    "\n",
    "def cross_entropy(a, y):\n",
    "    n = len(y)\n",
    "    y = y.reshape(n,1)\n",
    "    C = -(1/n)*np.sum(y*np.log(a)+(1-y)*np.log(1-a))\n",
    "    return C\n",
    "\n",
    "def d_cross_entropy(a, y):\n",
    "    n = len(y)\n",
    "    #y = y.reshape(n,1)\n",
    "    d_C = -(1/n)*np.sum((a-y)/((a-1)*a))\n",
    "    return  d_C\n",
    "\n",
    "\n",
    "\n",
    "#The goal is to set it up so that we can use BATCH, Mini-Batch, or SGD(batch size 1), depending on the input size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.565615222844391"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_output = np.array([.01,.9,.99,.01])\n",
    "# y_actual = np.array([1,0,0,1])\n",
    "\n",
    "#y_output = np.array([.9,0.1,0.1,.9])\n",
    "#y_actual = np.array([1,0,0,1])\n",
    "\n",
    "#y_output = np.array([.1,0.9,0.1,.9])\n",
    "#y_actual = np.array([1,0,0,1])\n",
    "\n",
    "y_output = np.array([.000009,.00001])\n",
    "y_actual = np.array([1,0])\n",
    "\n",
    "cross_entropy(y_output,y_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.41997434,  1.        ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_tanh(y_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "--Network Architecture--\n",
    "\n",
    "           IN(X)          FC1           A1           OUT           A2             SCORE\n",
    "SGD:      (1x4)          (1x10)       (1x10)        (1x1)         (1x1)           (1) \n",
    "BATCH:   (100x4)        (100x10)     (100x10)      (100x1)       (100x1)          (1)\n",
    "\n",
    "                  X*w0    >>  sig(fc1)  >>   a1*w1    >>  sig(out)  >>  mse(a2) >>\n",
    "                   (4x10)                      (10x1)\n",
    "Going to forego biases for now. Because the data is linearly seperable with lines through the origin,\n",
    "I think that this should work fine for this particular problem.  \n",
    "'''\n",
    "def forward(x,y_actual,w0,w1,b0,b1):\n",
    "    fc1 = x.dot(w0)+b0\n",
    "    #print('fc1: ',fc1.shape)\n",
    "    \n",
    "    a1 = sigmoid(fc1)\n",
    "    #print('a1: ',a1.shape)\n",
    "    \n",
    "    out = a1.dot(w1)+b1\n",
    "    #print('out: ',out.shape)\n",
    "    \n",
    "    a2 = sigmoid(out)\n",
    "    #print('a2: ',a2.shape)\n",
    "    \n",
    "    score = cross_entropy(a2, y_actual)\n",
    "    print('score: ',score)\n",
    "    \n",
    "    return x,y_actual,w0,w1,b0,b1,fc1,a1,out,a2,score\n",
    "\n",
    "def backward(x,y_actual,w0,w1,b0,b1,fc1,a1,out,a2,score,learning_rate):\n",
    "    print('d_cross_entropy',d_cross_entropy(a2,y_actual).shape)\n",
    "    print((a2-y_actual).shape)\n",
    "    \n",
    "    d_score_d_w1 = a1.T.dot(d_cross_entropy(a2,y_actual)*d_sigmoid(out))\n",
    "    #print(d_score_d_w1)\n",
    "    \n",
    "    d_score_d_b1 = d_cross_entropy(a2,y_actual)*d_sigmoid(out)\n",
    "    #print(d_score_d_w1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    d_score_d_w0 = X.T.dot((d_cross_entropy(a2,y_actual)*d_sigmoid(out)).dot(w1.T)*d_sigmoid(fc1))\n",
    "    #print(d_score_d_w0)\n",
    "    \n",
    "    d_score_d_b0 = (d_cross_entropy(a2,y_actual)*d_sigmoid(out)).dot(w1.T)*d_sigmoid(fc1)\n",
    "    #print(d_score_d_w0)\n",
    "    \n",
    "    w1 = w1 - learning_rate * d_score_d_w1\n",
    "    b1 = b1 - learning_rate * d_score_d_b1\n",
    "    w0 = w0 - learning_rate * d_score_d_w0\n",
    "    b0 = b0 - learning_rate * d_score_d_b0\n",
    "    \n",
    "    return x,y_actual,w0,w1,b0,b1,fc1,a1,out,a2,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "learning_rate = 0.01\n",
    "epochs = 4\n",
    "#batch_size = 100\n",
    "x = X\n",
    "y_actual = y#.reshape(100,1)\n",
    "#x = X[:5]\n",
    "#y_actual = y[:5]\n",
    "#x = X[3]\n",
    "w0 = (np.random.randn(4,2)-1)*.01\n",
    "b0 = (np.random.randn(len(x),2)-1)*.01\n",
    "w1 = (np.random.randn(2,1)-1)*.01\n",
    "b1 = (np.random.randn(len(x),1)-1)*.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Epoch , 0\n",
      "score:  0.693328451792\n",
      "-0.0163166764285 -0.00282373180554\n",
      "d_cross_entropy ()\n",
      "(100, 100)\n",
      "-0.0162541904626 0.0947594304675\n",
      "-----------Epoch , 1\n",
      "score:  0.694362110794\n",
      "-0.0162541904626 0.0947594304675\n",
      "d_cross_entropy ()\n",
      "(100, 100)\n",
      "0.00819442178896 -1.04309376825\n",
      "-----------Epoch , 2\n",
      "score:  0.840844429645\n",
      "0.00819442178896 -1.04309376825\n",
      "d_cross_entropy ()\n",
      "(100, 100)\n",
      "2.88323052909 10.6271640159\n",
      "-----------Epoch , 3\n",
      "score:  0.41728399936\n",
      "2.88323052909 10.6271640159\n",
      "d_cross_entropy ()\n",
      "(100, 100)\n",
      "48690124.6095 -5261855.40103\n"
     ]
    }
   ],
   "source": [
    "#batches = x   #Set batches to each individual x. (SGD)\n",
    "batches = [x] #Set batch to all of x.\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('-----------Epoch ,',epoch)\n",
    "    for i,batch in enumerate(batches):\n",
    "        x,y_actual,w0,w1,b0,b1,fc1,a1,out,a2,score = forward(x,y_actual,w0,w1,b0,b1) \n",
    "        #print(np.hstack((a2,y_actual.reshape(100,1)))[10:20])\n",
    "        print(w0[0][0],w1[0][0])\n",
    "        x,y_actual,w0,w1,b0,b1,fc1,a1,out,a2,score = backward(x,y_actual,w0,w1,b0,b1,fc1,a1,out,a2,score,learning_rate)\n",
    "        print(w0[0][0],w1[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 48690124.60946519  49917356.3427834 ]\n",
      " [ 93127825.54759592  95163065.36613226]\n",
      " [ 12553344.64016698  12968545.53337999]\n",
      " [ 12327625.78808711  12611096.60811755]]\n"
     ]
    }
   ],
   "source": [
    "print(w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.20657726   0.55146144   0.        ]\n",
      " [  0.20086575   0.55004828   0.        ]\n",
      " [  0.72520775   0.67375277   1.        ]\n",
      " [  0.24032316   0.55979329   0.        ]\n",
      " [  0.20733301   0.55164837   0.        ]\n",
      " [  0.21544666   0.55365429   0.        ]\n",
      " [ 11.08775825   0.9999847    1.        ]\n",
      " [  0.21635999   0.55387998   0.        ]\n",
      " [ 21.2898205    1.           1.        ]\n",
      " [ 14.02675227   0.99999919   1.        ]\n",
      " [ 12.22164556   0.99999508   1.        ]\n",
      " [ 21.36504214   1.           1.        ]\n",
      " [  0.20845299   0.55192536   0.        ]\n",
      " [  0.55080054   0.6343213    1.        ]\n",
      " [  0.21604101   0.55380116   0.        ]\n",
      " [ 21.40331961   1.           1.        ]\n",
      " [  0.21535547   0.55363175   0.        ]\n",
      " [ 15.41322189   0.9999998    1.        ]\n",
      " [ 13.81378916   0.999999     1.        ]\n",
      " [ 21.31272476   1.           1.        ]\n",
      " [  0.21991988   0.55475945   0.        ]\n",
      " [ 20.62321043   1.           1.        ]\n",
      " [  0.2052683    0.55113764   0.        ]\n",
      " [  0.22212522   0.5553041    0.        ]\n",
      " [  0.21585987   0.5537564    0.        ]\n",
      " [  0.228554     0.55689106   0.        ]\n",
      " [  7.7807097    0.99958246   1.        ]\n",
      " [  0.22965666   0.55716314   0.        ]\n",
      " [ 21.44418834   1.           1.        ]\n",
      " [  0.22542026   0.55611764   0.        ]\n",
      " [ 16.63246017   0.99999994   1.        ]\n",
      " [ 18.10489252   0.99999999   1.        ]\n",
      " [ 20.85199846   1.           1.        ]\n",
      " [  0.20433351   0.55090638   0.        ]\n",
      " [  0.22767576   0.55667434   0.        ]\n",
      " [  0.20991653   0.55228727   0.        ]\n",
      " [  0.20987079   0.55227596   0.        ]\n",
      " [ 21.45651519   1.           1.        ]\n",
      " [  0.20151928   0.55021002   0.        ]\n",
      " [  0.21994878   0.55476658   0.        ]\n",
      " [ 20.33715825   1.           1.        ]\n",
      " [ 20.46925174   1.           1.        ]\n",
      " [  0.20204086   0.55033909   0.        ]\n",
      " [  0.20333544   0.55065944   0.        ]\n",
      " [ 20.90967024   1.           1.        ]\n",
      " [ 19.20300291   1.           1.        ]\n",
      " [  0.2051856    0.55111718   0.        ]\n",
      " [  0.22639098   0.55635724   0.        ]\n",
      " [ 21.42173472   1.           1.        ]\n",
      " [  8.0924397    0.99969425   1.        ]\n",
      " [ 16.98351378   0.99999996   1.        ]\n",
      " [  0.2075676    0.55170639   0.        ]\n",
      " [  0.21276374   0.55299118   0.        ]\n",
      " [ 21.43144863   1.           1.        ]\n",
      " [ 21.47768964   1.           1.        ]\n",
      " [ 15.37530091   0.99999979   1.        ]\n",
      " [  0.20315857   0.55061567   0.        ]\n",
      " [  0.20773678   0.55174823   0.        ]\n",
      " [ 21.21050855   1.           1.        ]\n",
      " [  4.86983187   0.9923838    1.        ]\n",
      " [ 21.29644372   1.           1.        ]\n",
      " [  0.20764297   0.55172503   0.        ]\n",
      " [  4.73110048   0.99126029   1.        ]\n",
      " [  0.20603692   0.55132778   0.        ]\n",
      " [  0.73837281   0.67663993   1.        ]\n",
      " [  0.21712796   0.55406973   0.        ]\n",
      " [  0.19346324   0.54821552   0.        ]\n",
      " [  0.23538502   0.55857605   0.        ]\n",
      " [ 21.21667457   1.           1.        ]\n",
      " [ 19.74395086   1.           1.        ]\n",
      " [ 21.25922485   1.           1.        ]\n",
      " [  0.21246081   0.5529163    0.        ]\n",
      " [ 14.83780059   0.99999964   1.        ]\n",
      " [  0.19637529   0.54893666   0.        ]\n",
      " [ 18.77086069   0.99999999   1.        ]\n",
      " [ 21.47103208   1.           1.        ]\n",
      " [  9.42413165   0.99991925   1.        ]\n",
      " [  0.20670432   0.55149287   0.        ]\n",
      " [ 20.80103096   1.           1.        ]\n",
      " [ 13.40572648   0.99999849   1.        ]\n",
      " [ 15.58068558   0.99999983   1.        ]\n",
      " [  0.21957336   0.55467385   0.        ]\n",
      " [ 20.98751199   1.           1.        ]\n",
      " [  0.21619051   0.5538381    0.        ]\n",
      " [ 15.44099596   0.9999998    1.        ]\n",
      " [  0.23355813   0.55812555   0.        ]\n",
      " [  0.21061037   0.55245883   0.        ]\n",
      " [  0.19167632   0.54777291   0.        ]\n",
      " [  0.21259288   0.55294895   0.        ]\n",
      " [  0.20739233   0.55166304   0.        ]\n",
      " [  0.21219412   0.55285037   0.        ]\n",
      " [ 21.34316015   1.           1.        ]\n",
      " [  1.41707746   0.80487985   1.        ]\n",
      " [  0.19809901   0.54936343   0.        ]\n",
      " [ 12.63822069   0.99999675   1.        ]\n",
      " [  7.57511119   0.9994872    1.        ]\n",
      " [  0.20903834   0.55207011   0.        ]\n",
      " [ 21.37730333   1.           1.        ]\n",
      " [  0.21023274   0.55236546   0.        ]\n",
      " [  0.21477509   0.55348832   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.hstack((out,a2,y_actual.reshape(100,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for reference, a more thourough step by step way of back-propogating the gradients\n",
    "def backward_old(x,y_actual,w0,w1,fc1,a1,out,a2,score, learning_rate):\n",
    "    d_score_d_a2 = d_MSE(a2,y_actual)\n",
    "    #print('d_score_d_a2: ',d_score_d_a2.shape)\n",
    "    \n",
    "    d_a2_d_out = d_sigmoid(out)\n",
    "    #print('d_a2_d_out: ',d_a2_d_out.shape)\n",
    "    \n",
    "    d_out_d_a1 = w1\n",
    "    #print('d_out_d_a1: ',d_out_d_a1.shape)\n",
    "    \n",
    "    d_a1_d_fc1 = d_sigmoid(fc1)\n",
    "    #print('d_a1_d_fc1: ',d_a1_d_fc1.shape)\n",
    "\n",
    "    #Chains\n",
    "    d_score_d_out = d_score_d_a2 * d_a2_d_out\n",
    "    #  (5x1)           (1)            (5x1)\n",
    "    #print('d_score_d_out: ',d_score_d_out.shape)\n",
    "    \n",
    "    d_score_d_a1 = d_score_d_out.dot(d_out_d_a1.T)\n",
    "    #  (5x10)          (5x1)            (1x10)\n",
    "    #print('d_score_d_a1: ',d_score_d_a1.shape)\n",
    "    \n",
    "    d_score_d_fc1 = d_score_d_a1 * d_a1_d_fc1\n",
    "    #  (5x10)         (5x10)         (5x10)   \n",
    "    #print('d_score_d_fc1: ',d_score_d_fc1.shape)\n",
    "    \n",
    "    \n",
    "    #Weights\n",
    "    d_score_d_w1 = a1.T.dot(d_score_d_out)\n",
    "    #   (10x1)       (10x5)     (5x1)    \n",
    "    #print('d_score_d_w1: ',d_score_d_w1.shape)\n",
    "    print(d_score_d_w1)\n",
    "    \n",
    "    d_score_d_w0 = x.T.dot(d_score_d_fc1)\n",
    "    #   (4x10)    (4x5)      (5x10)\n",
    "    #print('d_score_d_w0: ',d_score_d_w0.shape)\n",
    "    print(d_score_d_w0)\n",
    "    \n",
    "    #Update Weights: Gradient Descent Step\n",
    "    \n",
    "    w1 += -learning_rate * d_score_d_w1\n",
    "    w0 += -learning_rate * d_score_d_w0\n",
    "    #print('Update:')\n",
    "    #print(-learning_rate * d_score_d_w1)\n",
    "    \n",
    "    #return x,y_actual,w0,w1,fc1,a1,out,a2,score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
